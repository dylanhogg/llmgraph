package_name = "llmgraph"
version = "1.3.0"
prompts_yaml_location = "prompts.yaml"

default_llm_model = "gpt-4o-mini"
default_llm_temp = 0.0
default_output_folder = "./_output/"
